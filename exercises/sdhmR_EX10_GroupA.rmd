---
title: "Exercise 10 Group A"
author: "Eli, Mia, Matt"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/mttft/Desktop/UVM/UVM Courses/SDHM_R/sdhmR-V2021.1EXP")
knitr::opts_chunk$set(warning=FALSE,error=TRUE,message=FALSE)
```

```{r include=F}
# Load packages
library(tidyverse)
library(data.table)
library(randomForest)
library(PresenceAbsence)
library(DAAG)

# Set working directories
path.root <- "C:/Users/mttft/Desktop/UVM/UVM Courses/SDHM_R/sdhmR-V2021.1EXP"
path.mod2 <- paste(path.root, "/data/module02", sep = "")
path.figs <- paste(path.root, "/powerpoints/figures", sep = "") 
path.gis <- paste(path.root, "/data/gis_layers", sep = "")
path.range <- paste(path.root, "/data/RangeData", sep = "")

# Load CRSs
setwd(path.root)
source("r_code/prjs4_sdhmR.r")
ls(pattern = "prj.")

# Load presence:pseudo-absence and predictor data
load(paste(path.root, "/data/RangeData/ShortRangeData.RData", sep = ""))

```

---

## Question #1

* Import and explore data
  * **NOTE**:  intent is not to reduce number of variables; that was completed in exercise #5.  Rather, calculate simple descriptive statistics (mean, sd, n) and boxplots

**Already done in ex 7 and 8**

---

## Question #2

* Construct a Random Forest (RF) model using the presence:absence data
* Build plots of variable importance values

```{r}
mod.form <- function(dat ,r.col, p.col) {
  # generic formula construction function; inputs as:
  #  resp =>col 1 in dataframe such that r.col=1, 
  #  preds=>col 2 thru ncol in dataframe such that p.col=2
  #  NOTE: predictor vars as factors; coerce PRIOR to formula construction
  # example call: mod.form(dat1,1,2)
   n.col <- ncol(dat) # No. columns in dataframe
   resp <- colnames(dat[r.col]) # assign resp column name
   resp <- paste("as.factor(", colnames(dat[r.col]), ")", sep = "") # assign resp column name
   pred <- colnames(dat[c(p.col:n.col)]) # assign preds column names
   mod.formula <- as.formula(paste(resp, "~", paste(pred, collapse = "+"))) # build formula 
}

mod1_RF <- randomForest(mod.form(r_dat, 2, 5), importance = T, 
    keep.forest = T, data = r_dat) # RF model w/mod.form fxn

mod1_pred <- predict(mod1_RF, type = "prob")[, 2] # predict from model
head(mod1_pred)
```

```{r}
# plot variable importance values
varImpPlot(mod1_RF)
```

---

## Question #3

* Calculate accuracy metrics (as in Module 3.2 and 3.3, Analytical Intermission) using:
  * Resubstitution approaches, and
  * A 10-fold cross--validation approach
* Extract the Out--of--Bag (OOB) estimate of model accuracy
* Compare that to the resubstitution and 10--fold cross--validation accuracy metrics

**Accuracy with Resubstitution**
```{r}
mod1 <- "RF"
dat1 <- cbind(mod1, r_dat[2], mod1_pred)
head(dat1, 2)

mod.cut <- optimal.thresholds(dat1, opt.methods = c("ReqSens"), req.sens = 0.95)
mod.cut

# generate confusion matrix
mod1_resub.cfmat <- table(dat1[[2]], factor(as.numeric(dat1$mod1_pred >= mod.cut$mod1_pred)))
mod1_resub.cfmat

# calculate model accuracies with standard deviation=F
mod1_resub.acc <- presence.absence.accuracy(dat1, threshold = mod.cut$mod1_pred, st.dev = F)
tss <- mod1_resub.acc$sensitivity + mod1_resub.acc$specificity - 1
mod1_resub.acc <- cbind(mod1_resub.acc[1:7], tss)
mod1_resub.acc[c(1, 4:5, 7:8)]

auc.roc.plot(dat1, color = T)
```

**Accuracy with 10-fold Cross Validation**
```{r}
# simple xfold code
set.seed(1234) # set.seed for repeatability
R_dat.xf <- sample(rep(c(1:10), length = nrow(r_dat))) # vector of random xfolds
mod1.predXF <- rep(0, length = nrow(r_dat)) # empty vector of 0
xfold <- 10 # set No. xfolds
# simple loop for xfold
for (i in 1:xfold) {
  tr <- r_dat[R_dat.xf != i, ] # training not eq. i
  te <- r_dat[R_dat.xf == i, ] # test eq. i
  RF <- randomForest(mod.form(r_dat, 2, 5), importance = T, 
    keep.forest = T, data = r_dat) # maxent model on training
  mod1.predXF[R_dat.xf == i] <- predict(RF, te) # predict to test
}
head(mod1.predXF) # examine vector xfold prediction 

# generate confusion matrix; see help(theshold) for maxent threshold options
modl
dat2XF <- cbind(modl, r_dat[2], mod1.predXF) # build dataframe w/mod1 predictions
head(dat2XF, 2) # examine prediction dataframe
mod_cut.cv <- optimal.thresholds(dat2XF, opt.methods = c("ObsPrev"))
mod_cut.cv # view RF thresholds
mod1.cfmatXF <- table(dat2XF[[2]], factor(as.numeric(dat2XF$mod1.predXF >= mod_cut.cv$mod1.predXF)))
mod1.cfmatXF

# calculate model accuracies with standard deviation=F
mod1.accXF <- presence.absence.accuracy(dat2XF, threshold = mod.cut[[2]], st.dev = F)
tss <- mod1.accXF$sensitivity + mod1.accXF$specificity - 1 # code TSS metric
mod1.accXF <- cbind(mod1.accXF[1:7], tss) # bind all metrics
mod1.accXF[c(1, 4:5, 7:8)] # examine accuracies 
```

```{r}
# # CVbinary function did not work
# dat2 <- cbind(mod1, r_dat[2], mod1_pred)
# 
# # prediction and validation
# set.seed(1234)
# mod1_cv <- CVbinary(mod1_RF, nfolds = 10, print.details = F)
# mod1_cv <- mod1_cv$cvhat
# dat2 <- cbind(dat2[,1:2], mod1_cv)
# head(dat2)
# 
# # generate confusion matrix
# mod1_cv.cfmatJ <- table(dat2[[2]], factor(as.numeric(dat2$mod1_cv >= mod.cut$mod1_pred)))
# mod1_cv.cfmatJ
# 
# # calculate model accuracy with standard deviation=F
# mod1_cv.accB <- presence.absence.accuracy(dat2,
#                                                  threshold = mod.cut$mod1_pred,
#                                                  st.dev = F)
# tss <- mod1_cv.accB$sensitivity + mod1_cv.accB$specificity - 1
# mod1_cv.accB <- cbind(mod1_cv.accB[1:7], tss)
# mod1_cv.accB[c(1, 4:5, 7:8)]
# 
# GAM2_acc.sum = rbind(PartRange_GAM2.acc, mod1_cv.accB)
```

**Out--of--Bag (OOB) estimate of model accuracy**
```{r}
mod1_RF            # OOB estimate of error rate: 27.38%

mod1_RF$confusion  # 44% error for presence data, 19% error for absence data

oob.acc <- presence.absence.accuracy(dat2, st.dev = F) # oob accuracies
tss <- oob.acc$sensitivity + oob.acc$specificity - 1 # code TSS metric
oob.acc <- cbind(oob.acc[1:7], tss) # bind all metrics
oob.acc[c(1, 4:5, 7:8)] # examine accuracies

# bind accuracies
total_acc <- rbind(mod1_resub.acc,mod1.accXF, oob.acc)
total_acc

total_acc$model[3] = "mod1_oob"
```


---

## Question #4

* Build 2 prediction maps:
  * A raw probability estimate for each cell in the modelling domain; and
  * A classified map based on the selected threshold from Question #3

```{r}
#   ASSUME pred.dom is a raster stack per Module 4.1
rang_probRF <- predict(r_dom, 
                          mod1_RF, 
                          filename = "PartRange.ProbRF.img",
                          type = "prob", 
                          fun = predict, 
                          index = 2, 
                          overwrite = T)

setwd(path.gis)
states <- st_read(dsn = ".", layer = "na_states_wgs")

plot(rang_probRF, legend = T, axes = T, main = "Probability Map")
plot(st_geometry(states), add = T, lwd = 1.5)
```

**Classification Map**
```{r}
rang_clasRF <- reclassify(rang_probRF, 
                             filename = "PartRange.ClasRF.img",
                             (c(0, mod.cut[[2]], 0, mod.cut[[2]], 1, 1)),
                             overwrite = T) # class map

plot(rang_clasRF, legend = T, axes = T, main = "Classification Map")
plot(st_geometry(states), add = T, lwd = 1.5)
```

---

## Question #5

* Save your data as R objects:
  * Accuracy metrics as a dataframe;
  * Classification threshold as a stand--alone scalar
  * Both prediction maps as **`.img`** format
* Save these R objects in a **`.RData`** file

These data will be used again in Module 10, Ensemble Models.

```{r}
mod.cut_RF <- mod.cut$mod1_pred

save(mod1_RF,
     total_acc,
     mod.cut_RF, 
     rang_probRF,
     rang_clasRF,
     file = "C:/Users/mttft/Desktop/UVM/UVM Courses/SDHM_R/sdhmR-V2021.1EXP/data/RangeData/RF_Results.Rdata")


```

---

## The End

---
