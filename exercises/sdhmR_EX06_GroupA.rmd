---
title: "Exercise 6: Exploring the Training Dataframe"
author: "Group A: Eli Polzer, Matt Futia, Mia McReynolds"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_knit$set(root.dir = "~/University of Vermont/Classes/sdhmR/sdhmR-V2021.1")
#knitr::opts_knit$set(root.dir = "~/sdhmR-V2020.2")
knitr::opts_chunk$set(warning=FALSE,error=TRUE,message=FALSE)
```

```{r}
# some pathnames; yours will be specific to your CPU !!
  path.root <- "~/University of Vermont/Classes/sdhmR/sdhmR-V2021.1" 
  
# below is the recommended class root dir
  #path.root <- "~/sdhmR-V2021.1"  # typical class root dir
  path.mod2 <- paste(path.root, "/data/module02", sep = "")
  path.figs <- paste(path.root, "/powerpoints/figures", sep = "") 
  path.gis <- paste(path.root, "/data/gis_layers", sep = "")
  
# some libraries
  library(sf)
  library(tidyverse)
  library(data.table)
  library(modeest)
```

## Question #1

* Break the predictor variables into logical groups of **topography**, **temperature**, and **precipitation**.  Do this by creating a new column called **`pred_type`** and add it the dataframe.

```{r}
# Load presence:pseudo-absence and predictor data
load(paste(path.mod2, "/range_pres_psu_data.RData", sep = ""))
```
I'm not going to add a new column, to preserve data structure, but groupings are (based on the HTML doc): 

**topography** = "exp1nrm.img"    "exp3nrm.img"    "exp5nrm.img" "prad_sw_di.img" "rough_1k.img"  "topos.img" 

**temperature** =   "tave_s_hal.img" "tave_sprin.img" "tmax_s_hal.img" "tmax_summe.img" 

**precipitation** = "etpt_5.img", "etpt_6.img", "etpt_sprin.img" "prec_w_hal.img" "prec_winte.img" "mind_yr_av.img"

Add groupings using Matt's code:
```{r}
all_data = range_PPsA_ShortData
pred_groups = data.frame(names(all_data[,18:33]))
names(pred_groups) = "Variable"
topo = c("exp1nrm","exp3nrm","exp5nrm","prad_sw_di","rough_1k","topos")
temp = c("tave_s_hal","tave_sprin","tmax_s_hal","tmax_summe")
precip = c("etpt_5","etpt_6","etpt_sprin","mind_yr_av","prec_w_hal","prec_winte")
pred_groups$pred_type = if_else(pred_groups$Variable %in% topo,"topography",
                                if_else(pred_groups$Variable %in% temp,"temperature", "precipitation"))
```



---

## Question #2

* Assess correlations:
  * Among all variables; and
  * Within each of the logical groupings created above
  
```{r}
# numeric correlations
  cut.point <- 0.7 # set cutpoint for correlation
  c1 <- cor(all_data[, c(18:33)], use = "pairwise.complete.obs", 
    method = "spearman") # est. correlation
  c1 # examine
```

```{r}
  c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
  c2 # examine; FALSE indicates cor<cutpoint 
```

```{r}
# START MODIFIED panel.cor CORRELATION FUNCTION		   
panel.cor <- function(x, y, digits=2, prefix="", cex.cor) 
  { usr <- par("usr"); on.exit(par(usr)) 
    par(usr = c(0, 1, 0, 1)) 
    r <- abs(cor(x, y, use = "pairwise.complete.obs")) 
    txt <- format(c(r, 0.123456789), digits=digits)[1] 
    txt <- paste(prefix, txt, sep="") 
    if(missing(cex.cor)) cex <- 0.8/strwidth(txt) 

    test <- cor.test(x,y) 
    # borrowed from printCoefmat
    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, 
                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                  symbols = c("***", "**", "*", ".", " ")) 

    text(0.5, 0.5, txt, cex = cex * r)
    text(.8, .8, Signif, cex=cex, col=2) 
  }

# plot correlations using modified panel.cor function
  pairs(all_data[, c(18:33)], lower.panel = panel.smooth,
  upper.panel = panel.cor, main = "Topo Variables")

```
  
The panel plot of all variables' correlations is pretty hard to see here, but zooming in it looks like several are correlated, and several have "significant" but unimportant correlations. I'll look at groups of predictors for a better examination of correlations, and come back to this when selecting final set of predictors. 


```{r}
# numeric correlations
  cut.point <- 0.7 # set cutpoint for correlation
  c1 <- cor(dplyr::select(all_data, one_of(topo)), use = "pairwise.complete.obs", 
    method = "spearman") # est. correlation
  c1 # examine
  c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
  c2 # examine; FALSE indicates cor<cutpoint 

# plot correlations using modified panel.cor function
  pairs(dplyr::select(all_data, one_of(topo)), lower.panel = panel.smooth,
  upper.panel = panel.cor, main = "Topo Variables")
```

First, topography: exp1 and exp3, exp3 and exp5, exp5 and topos are strongly correlated. 

```{r}
# numeric correlations
  cut.point <- 0.7 # set cutpoint for correlation
  c1 <- cor(dplyr::select(all_data, one_of(temp)), use = "pairwise.complete.obs", 
    method = "spearman") # est. correlation
  c1 # examine
  c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
  c2 # examine; FALSE indicates cor<cutpoint 

# plot correlations using modified panel.cor function
  pairs(dplyr::select(all_data, one_of(temp)), lower.panel = panel.smooth,
  upper.panel = panel.cor, main = "Temp Variables")
```

Second, temperature: all of these variables are significantly correlated. 

```{r}
# numeric correlations
  cut.point <- 0.7 # set cutpoint for correlation
  c1 <- cor(dplyr::select(all_data, one_of(precip)), use = "pairwise.complete.obs", 
    method = "spearman") # est. correlation
  c1 # examine
  c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
  c2 # examine; FALSE indicates cor<cutpoint 

# plot correlations using modified panel.cor function
  pairs(dplyr::select(all_data, one_of(precip)), lower.panel = panel.smooth,
  upper.panel = panel.cor, main = "Precip Variables")
```

Third, precipitation: etpt 5, 6, and spring were all correlated. prec_w_hal and prec_winter were correlated. ALso a lot of others had moderate correlation around 0.5-0.6, a little lower than the 0.7 cutoff but still should be considered. 


---

## Question #3

* Examine variable importance of each predictor variable as related to presence:absence using the process described in the Module. (Within each of the variable groups). 

```{r}
#### START function variable importance
varimp.glm <- function(tr.spp, tr.var, pres, pf, pl) {
  tmp.mat <- matrix(ncol = 2, nrow = (pl - pf + 1))
  for (i in pf:pl) {
    # option: linear+quadratic; linear only
    tmp <- glm(tr.spp[, pres] ~ tr.var[, i] + I((tr.var[, i])^2), na.action = na.omit, 
      family = binomial)
    # linear only glm
    #tmp <- glm(tr.spp[, pres] ~ tr.var[, i], na.action = na.omit, family = binomial)
    tmp.mat[(i - pf + 1), 1] <- tmp$aic
    tmp.mat[(i - pf + 1), 2] <- (1 - (tmp$deviance/tmp$null.deviance))
    }
  return(tmp.mat)
  } 
#### END function variable importance
```

```{r}
# estimate VIP values => AIC & Adj deviance
  tr.vip <- as.data.frame(all_data[,c(2, 18:33)]) # keep only P/A & predictors - had to make this a df to get GLM to work
  pres <- 1 # column for presence:absence
  v.start <- 2 # column start predictor variables
  v.stop <- ncol(tr.vip) # last column predictor variables
  v.num <- v.stop - 1 # number predictor variables
  dev.fit <- varimp.glm(tr.vip, tr.vip, pres, v.start, v.stop) # call VIP function
  
  dev.fit01 <- data.frame(pred_groups, dev.fit)
  dev.fit01

# built basic barplot if desired
d.max <- ceiling(signif(max(dev.fit[, 2]), 2) * 10)/10 # max of y-axis
ylim.r <- range(0, d.max) # range y-axis
x.labs <- names(tr.vip[2:v.stop]) # x-axis labels

 barplot(dev.fit[, 2], col = "darkgreen", ylim = ylim.r, main = "all VIPs",
  ylab = "adj.D2", names = x.labs, las=2) # barplot - las=2 rotates labels
abline(h = 0) # add horizontal line
abline(mean(dev.fit[, 2]), 0, lt = 3) # ref lines; dash=mean adj.dev
```


---

## Question #4

* Eliminate redundant variables with a goal of retaining 7-10 of the 16 available (keeping at least a couple in each of the categories)
* Justify your decision(s) to keep / remove variables using bullets

```{r}
remove = c("etpt_6", "etpt_sprin", "prec_winte", "tave_s_hal", "tave_sprin", "tmax_summe", "exp1nrm", "exp3nrm", "exp5nrm")

tr_RANG <-all_data %>% 
  dplyr::select(-c(wgs_xF:tave_s_hal.x, cell.wgs_x, cell.wgs_y)) %>% 
  dplyr::select(-c(etpt_6, etpt_sprin, prec_winte, tave_s_hal, tave_sprin, tmax_summe, exp1nrm, exp3nrm, exp5nrm))
```

<!

<!-- * mind_yr_av: highly correlated to etpt vars, and a moisture index that is likely modeled, so this is my reluctant 7th choice for variables list. Has a high VIP though.  -->

--> This has been updated: see Matt's code for our group's rationale (I'd used wrong input data). 
---

## Question #5

* Include the term **tr_MORT**, **tr_PERS**, **tr_RANG**, and **tr_SEED** somewhere in the final training data objects, depending on your data group.  Use of **tr_ByGroup** here means the data are now ready for model creation.
* Save your data as R objects:
  * Dataframe;
  * Point shapefile with geometry in R
  * Export as a point shapefile in ESRI format
* Save these R objects in a **`.RData`** file

These data will be used as we next begin the SDHM model constructions.

```{r}
# write out data files if desired
  setwd(path.mod2)

  # Convert data.frame to shapefile
tr_RANG_SF <- st_as_sf(tr_RANG, coords = c("tr.wgs_x", "tr.wgs_y"), crs = prj.wgs84, remove = F)

save(tr_RANG, tr_RANG_SF, file = "tr_RANG.Rdata")
  write.csv(tr_RANG, file = "tr_RANG.csv", row.names = F) # save .csv - training data
  

  st_write(tr_RANG_SF, dsn = ".", layer = "tr_RANG", driver = "ESRI Shapefile",
    delete_layer = T, delete_dsn = T) #point shapefile in ESRI format
```

---

## The End

---
